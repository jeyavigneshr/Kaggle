{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90274,"databundleVersionId":10995111,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:39:45.440245Z","iopub.execute_input":"2025-02-22T17:39:45.440544Z","iopub.status.idle":"2025-02-22T17:39:45.899952Z","shell.execute_reply.started":"2025-02-22T17:39:45.440484Z","shell.execute_reply":"2025-02-22T17:39:45.898900Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e2/sample_submission.csv\n/kaggle/input/playground-series-s5e2/train.csv\n/kaggle/input/playground-series-s5e2/test.csv\n/kaggle/input/playground-series-s5e2/training_extra.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\nimport collections\nimport string # library used to deal with text data\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:39:45.901020Z","iopub.execute_input":"2025-02-22T17:39:45.901725Z","iopub.status.idle":"2025-02-22T17:39:45.905699Z","shell.execute_reply.started":"2025-02-22T17:39:45.901680Z","shell.execute_reply":"2025-02-22T17:39:45.904685Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import seaborn as sns # data visualization library\nimport matplotlib.pyplot as plt # plotting library\nimport plotly.graph_objs as go # interactive plotting library\nimport plotly.express as px # interactive plotting library\nfrom itertools import cycle # used for cycling colors at plotly graphs\n# import pandas_profiling # library for automatic EDA\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:39:45.906820Z","iopub.execute_input":"2025-02-22T17:39:45.907199Z","iopub.status.idle":"2025-02-22T17:39:48.051482Z","shell.execute_reply.started":"2025-02-22T17:39:45.907166Z","shell.execute_reply":"2025-02-22T17:39:48.050492Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from scipy import stats # statistical library\nfrom statsmodels.stats.weightstats import ztest # statistical function for hypothesis testing\n\n\nfrom IPython.display import display # display from IPython.display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:39:48.052455Z","iopub.execute_input":"2025-02-22T17:39:48.052951Z","iopub.status.idle":"2025-02-22T17:39:48.081312Z","shell.execute_reply.started":"2025-02-22T17:39:48.052926Z","shell.execute_reply":"2025-02-22T17:39:48.080375Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Importing the data and displaying some rows\ndf1 = pd.read_csv(\"/kaggle/input/playground-series-s5e2/train.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/playground-series-s5e2/training_extra.csv\")\ndf = pd.concat([df1, df2], ignore_index=True)\ndisplay(df.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:39:48.084172Z","iopub.execute_input":"2025-02-22T17:39:48.084469Z","iopub.status.idle":"2025-02-22T17:39:57.876989Z","shell.execute_reply.started":"2025-02-22T17:39:48.084434Z","shell.execute_reply":"2025-02-22T17:39:57.876006Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"   id         Brand   Material    Size  Compartments Laptop Compartment  \\\n0   0      Jansport    Leather  Medium           7.0                Yes   \n1   1      Jansport     Canvas   Small          10.0                Yes   \n2   2  Under Armour    Leather   Small           2.0                Yes   \n3   3          Nike      Nylon   Small           8.0                Yes   \n4   4        Adidas     Canvas  Medium           1.0                Yes   \n5   5          Nike     Canvas  Medium          10.0                 No   \n6   6          Nike        NaN   Large           3.0                 No   \n7   7          Puma     Canvas   Small           1.0                Yes   \n8   8  Under Armour  Polyester  Medium           8.0                Yes   \n9   9  Under Armour      Nylon  Medium           2.0                Yes   \n\n  Waterproof      Style  Color  Weight Capacity (kg)      Price  \n0         No       Tote  Black             11.611723  112.15875  \n1        Yes  Messenger  Green             27.078537   68.88056  \n2         No  Messenger    Red             16.643760   39.17320  \n3         No  Messenger  Green             12.937220   80.60793  \n4        Yes  Messenger  Green             17.749338   86.02312  \n5        Yes        NaN  Black              7.241812   20.01553  \n6         No   Backpack  Green              6.828123   84.80500  \n7        Yes   Backpack   Blue             21.488864   27.15815  \n8         No       Tote   Gray             10.207780   25.98652  \n9        Yes  Messenger   Pink             15.895100   38.48741  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Brand</th>\n      <th>Material</th>\n      <th>Size</th>\n      <th>Compartments</th>\n      <th>Laptop Compartment</th>\n      <th>Waterproof</th>\n      <th>Style</th>\n      <th>Color</th>\n      <th>Weight Capacity (kg)</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Jansport</td>\n      <td>Leather</td>\n      <td>Medium</td>\n      <td>7.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Black</td>\n      <td>11.611723</td>\n      <td>112.15875</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Jansport</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>10.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>27.078537</td>\n      <td>68.88056</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Under Armour</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Red</td>\n      <td>16.643760</td>\n      <td>39.17320</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Nike</td>\n      <td>Nylon</td>\n      <td>Small</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>12.937220</td>\n      <td>80.60793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Adidas</td>\n      <td>Canvas</td>\n      <td>Medium</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>17.749338</td>\n      <td>86.02312</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Nike</td>\n      <td>Canvas</td>\n      <td>Medium</td>\n      <td>10.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>NaN</td>\n      <td>Black</td>\n      <td>7.241812</td>\n      <td>20.01553</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Nike</td>\n      <td>NaN</td>\n      <td>Large</td>\n      <td>3.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Backpack</td>\n      <td>Green</td>\n      <td>6.828123</td>\n      <td>84.80500</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Puma</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Blue</td>\n      <td>21.488864</td>\n      <td>27.15815</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Under Armour</td>\n      <td>Polyester</td>\n      <td>Medium</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Gray</td>\n      <td>10.207780</td>\n      <td>25.98652</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>Under Armour</td>\n      <td>Nylon</td>\n      <td>Medium</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Pink</td>\n      <td>15.895100</td>\n      <td>38.48741</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# # The pandas profiling library is really useful on helping us understand the data we're working on.\n# # It saves us some precious time on the EDA process.\n# report = pandas_profiling.ProfileReport(df)\n\n# # Let's now visualize the report generated by pandas_profiling.\n# display(report)\n\n# # Also, there is an option to generate an .HTML file containing all the information generated by the report.\n# # report.to_file(output_file='report.html')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:39:57.878708Z","iopub.execute_input":"2025-02-22T17:39:57.878984Z","iopub.status.idle":"2025-02-22T17:39:57.882451Z","shell.execute_reply.started":"2025-02-22T17:39:57.878962Z","shell.execute_reply":"2025-02-22T17:39:57.881546Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df.info(), df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:39:57.883409Z","iopub.execute_input":"2025-02-22T17:39:57.883699Z","iopub.status.idle":"2025-02-22T17:39:59.224974Z","shell.execute_reply.started":"2025-02-22T17:39:57.883670Z","shell.execute_reply":"2025-02-22T17:39:59.224102Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3994318 entries, 0 to 3994317\nData columns (total 11 columns):\n #   Column                Dtype  \n---  ------                -----  \n 0   id                    int64  \n 1   Brand                 object \n 2   Material              object \n 3   Size                  object \n 4   Compartments          float64\n 5   Laptop Compartment    object \n 6   Waterproof            object \n 7   Style                 object \n 8   Color                 object \n 9   Weight Capacity (kg)  float64\n 10  Price                 float64\ndtypes: float64(3), int64(1), object(7)\nmemory usage: 335.2+ MB\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(None,\n id                           0\n Brand                   126758\n Material                110962\n Size                     87785\n Compartments                 0\n Laptop Compartment       98533\n Waterproof               94324\n Style                   104180\n Color                   133617\n Weight Capacity (kg)      1808\n Price                        0\n dtype: int64)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# from sklearn.impute import SimpleImputer\n\n# # Handling categorical missing values using mode (most frequent value)\n# categorical_cols = [\"Brand\", \"Material\", \"Size\", \"Laptop Compartment\", \"Waterproof\", \"Style\", \"Color\"]\n# cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n# df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])\n\n# # Handling numerical missing values using median\n# num_imputer = SimpleImputer(strategy=\"median\")\n# df[\"Weight Capacity (kg)\"] = num_imputer.fit_transform(df[[\"Weight Capacity (kg)\"]])\n\n# # Confirm if missing values are handled\n# df.isnull().sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:39:59.225837Z","iopub.execute_input":"2025-02-22T17:39:59.226080Z","iopub.status.idle":"2025-02-22T17:39:59.229678Z","shell.execute_reply.started":"2025-02-22T17:39:59.226061Z","shell.execute_reply":"2025-02-22T17:39:59.228753Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\nfrom category_encoders import LeaveOneOutEncoder, TargetEncoder\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n\n\n# Define Features and Target\ntarget = df[\"Price\"]\ndf.drop(columns=[\"Price\"], inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:39:59.230468Z","iopub.execute_input":"2025-02-22T17:39:59.230835Z","iopub.status.idle":"2025-02-22T17:40:08.919790Z","shell.execute_reply.started":"2025-02-22T17:39:59.230802Z","shell.execute_reply":"2025-02-22T17:40:08.918713Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:40:08.920886Z","iopub.execute_input":"2025-02-22T17:40:08.921770Z","iopub.status.idle":"2025-02-22T17:40:08.933071Z","shell.execute_reply.started":"2025-02-22T17:40:08.921730Z","shell.execute_reply":"2025-02-22T17:40:08.931878Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3994318 entries, 0 to 3994317\nData columns (total 10 columns):\n #   Column                Dtype  \n---  ------                -----  \n 0   id                    int64  \n 1   Brand                 object \n 2   Material              object \n 3   Size                  object \n 4   Compartments          float64\n 5   Laptop Compartment    object \n 6   Waterproof            object \n 7   Style                 object \n 8   Color                 object \n 9   Weight Capacity (kg)  float64\ndtypes: float64(2), int64(1), object(7)\nmemory usage: 304.7+ MB\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Identify Numeric and Categorical Columns\nnumeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\ncategorical_columns = df.select_dtypes(include=[object]).columns.tolist()\nprint(numeric_columns)\nprint(categorical_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:40:08.934355Z","iopub.execute_input":"2025-02-22T17:40:08.934748Z","iopub.status.idle":"2025-02-22T17:40:10.236055Z","shell.execute_reply.started":"2025-02-22T17:40:08.934709Z","shell.execute_reply":"2025-02-22T17:40:10.235152Z"}},"outputs":[{"name":"stdout","text":"['id', 'Compartments', 'Weight Capacity (kg)']\n['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Split Data (Before Applying Transformations)\nx_train, x_test, y_train, y_test = train_test_split(df, target, test_size=0.10, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:40:10.236839Z","iopub.execute_input":"2025-02-22T17:40:10.237084Z","iopub.status.idle":"2025-02-22T17:40:13.458080Z","shell.execute_reply.started":"2025-02-22T17:40:10.237064Z","shell.execute_reply":"2025-02-22T17:40:13.457311Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n\ndef fill_na_with_decision_trees(df, numeric_cols, categorical_cols):\n    df_copy = df.copy()\n    \n    # Dictionary to store LabelEncoders for categorical columns\n    label_encoders = {}\n\n    # Encode categorical columns first\n    for col in categorical_cols:\n        le = LabelEncoder()\n        df_copy[col] = df_copy[col].astype(str)  # Convert to string (avoid NaN issues)\n        df_copy[col] = le.fit_transform(df_copy[col])  # Convert to numbers\n        label_encoders[col] = le  # Store encoder for inverse transformation\n\n    # Fill missing values in numerical columns using DecisionTreeRegressor\n    for col in numeric_cols:\n        if df_copy[col].isnull().sum() > 0:\n            dt_reg = DecisionTreeRegressor(max_depth=5, random_state=42)\n            known_data = df_copy[df_copy[col].notna()]\n            unknown_data = df_copy[df_copy[col].isna()]\n\n            feature_cols = [c for c in known_data.columns if c != col]\n\n            if known_data.shape[0] > 1 and not known_data[feature_cols].empty:\n                dt_reg.fit(known_data[feature_cols], known_data[col])\n                df_copy.loc[df_copy[col].isna(), col] = dt_reg.predict(unknown_data[feature_cols])\n\n    # Fill missing values in categorical columns using DecisionTreeClassifier\n    for col in categorical_cols:\n        if df_copy[col].isnull().sum() > 0:\n            dt_clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n            known_data = df_copy[df_copy[col].notna()]\n            unknown_data = df_copy[df_copy[col].isna()]\n\n            feature_cols = [c for c in known_data.columns if c != col]\n\n            if known_data.shape[0] > 1 and not known_data[feature_cols].empty:\n                dt_clf.fit(known_data[feature_cols], known_data[col])\n                df_copy.loc[df_copy[col].isna(), col] = dt_clf.predict(unknown_data[feature_cols])\n\n    # Convert categorical columns back to original labels\n    for col in categorical_cols:\n        df_copy[col] = label_encoders[col].inverse_transform(df_copy[col].astype(int))\n\n    return df_copy\n\n# Apply the function to train & test data\nx_train = fill_na_with_decision_trees(x_train, numeric_columns, categorical_columns)\nx_test = fill_na_with_decision_trees(x_test, numeric_columns, categorical_columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:40:13.458925Z","iopub.execute_input":"2025-02-22T17:40:13.459215Z","iopub.status.idle":"2025-02-22T17:40:31.578880Z","shell.execute_reply.started":"2025-02-22T17:40:13.459188Z","shell.execute_reply":"2025-02-22T17:40:31.578054Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# 1st -> Numeric Transformers\nnumeric_transformer = Pipeline([\n    ('scaler', MinMaxScaler())\n])\n\n# 2nd -> Categorical Transformers\ncategorical_transformer = Pipeline([\n    ('leaveoneout', LeaveOneOutEncoder(sigma=0.1))\n])\n\n# 3rd -> Combining Numeric & Categorical Pipelines\ndata_transformations = ColumnTransformer([\n    ('num', numeric_transformer, numeric_columns),\n    ('cat', categorical_transformer, categorical_columns)\n])\n\n# 4th -> Pipeline & RandomizedSearchCV\npipe = Pipeline([\n    ('data_transformations', data_transformations),\n    ('reg', RandomForestRegressor())  # Placeholder model\n])\n\nparams_grid = [\n    {'reg': [RandomForestRegressor()],\n     'reg__n_estimators': [int(x) for x in np.linspace(10, 100, num=10)],\n     'reg__max_features': [None, \"sqrt\", \"log2\"],\n     'reg__max_depth': [int(x) for x in np.linspace(5, 20, num=5)],\n     'reg__random_state': [42]},\n\n    {'reg': [LGBMRegressor()],\n     'reg__n_estimators': [int(x) for x in np.linspace(10, 100, num=10)],\n     'reg__max_depth': [int(x) for x in np.linspace(3, 15, num=5)],\n     'reg__learning_rate': np.linspace(0.01, 0.3, num=5)},\n\n    {'reg': [XGBRegressor()],\n     'reg__n_estimators': [int(x) for x in np.linspace(10, 100, num=10)],\n     'reg__max_depth': [int(x) for x in np.linspace(3, 15, num=5)],\n     'reg__learning_rate': np.linspace(0.01, 0.3, num=5),\n     'reg__gamma': np.linspace(0, 1, num=5),\n     'reg__lambda': np.linspace(0.1, 1, num=5)}\n]\n\n# Cross Validator\ncross_validator = StratifiedShuffleSplit(n_splits=5, train_size=0.8, test_size=0.2, random_state=7)\n\n# RandomizedSearchCV\nbest_model_pipeline = RandomizedSearchCV(\n    estimator=pipe,\n    param_distributions=params_grid,\n    n_iter=50,\n    scoring='r2',\n    refit=True,\n    n_jobs=-1,\n    cv=5,\n    random_state=21,\n    error_score='raise',\n    return_train_score=False\n)\n\n# Train Best Model\nbest_model_pipeline.fit(x_train, y_train)\n\n# Evaluate Best Model\ny_pred = best_model_pipeline.best_estimator_.predict(x_test)\n\nr2 = r2_score(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\n\nprint(\"\\n\\n#---------------- Best Regression Model Found ----------------#\\n\\n\", best_model_pipeline.best_estimator_[1])\nprint(\"\\n\\n#---------------- Best Estimator's R² Score ----------------#\\n\\n\", r2)\nprint(\"\\n\\n#---------------- Mean Absolute Error (MAE) ----------------#\\n\\n\", mae)\nprint(\"\\n\\n#---------------- Root Mean Squared Error (RMSE) ----------------#\\n\\n\", rmse)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:40:31.579866Z","iopub.execute_input":"2025-02-22T17:40:31.580160Z","execution_failed":"2025-02-22T18:57:59.485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/playground-series-s5e2/test.csv\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-22T18:57:59.485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test = fill_na_with_decision_trees(df_test, numeric_columns, categorical_columns)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-22T18:57:59.485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions = best_model_pipeline.best_estimator_.predict(df_test)\ndf_submission = pd.read_csv(\"/kaggle/input/playground-series-s5e2/test.csv\")\n\ndf_submission['Price'] = test_predictions # Adding a column with predicted values\n\ndf_submission.drop(df_submission.columns.difference(['id', 'Price']), axis=1, inplace=True) # Selecting only needed columns\n\ndf_submission.head(10)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-22T18:57:59.485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_submission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-22T18:57:59.485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_submission","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-22T18:57:59.485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}